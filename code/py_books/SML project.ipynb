{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np \n",
    "import contractions\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.externals import joblib\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "tokenizer = RegexpTokenizer('[A-Za-z0-9]?\\w+')\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pickle.load(open(\"Dataset\\\\metadata\",'rb'))\n",
    "Keyword = pickle.load(open(\"Dataset\\\\Keyword\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = pickle.load(open(\"rating_small_dict1\",'rb'))\n",
    "movie_ids = []\n",
    "for user in user_ratings.keys():\n",
    "    movie_ids += list(user_ratings[user].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ids = set(movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4320"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = dict()\n",
    "for movie_id in movie_ids:\n",
    "    movies[movie_id] = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(doc):\n",
    "    doc = contractions.fix(doc)\n",
    "    tokens = tokenizer.tokenize(doc)\n",
    "    normalized_tokens = []\n",
    "    for token in tokens:\n",
    "        token = token.lower()\n",
    "        if token == '' or token == '.' or token == '_' or token in stop_words:\n",
    "            continue\n",
    "        token = lemmatizer.lemmatize(token)\n",
    "        normalized_tokens.append(token)\n",
    "    return normalized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movies_with_keytems(keyword_doc, movies):\n",
    "    for row in keyword_doc:\n",
    "        movie_id = int(row[0])\n",
    "        if movies.get(movie_id) is None:\n",
    "            continue\n",
    "        keyterms = list()\n",
    "        movie_keyterm_dic_list = ast.literal_eval(row[1])\n",
    "        for movie_keyterm_dic in movie_keyterm_dic_list:\n",
    "            keyterms.append(movie_keyterm_dic['name'])\n",
    "        movies[movie_id][\"keyterms\"] = keyterms\n",
    "    return movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_with_keyterms = get_movies_with_keytems(Keyword, movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = 0\n",
    "# for k in movies_with_keyterms.keys():\n",
    "# #     print(movies_with_keyterms[k])\n",
    "#     if movies_with_keyterms[k].get(\"keyterms\") is None:\n",
    "#         c += 1\n",
    "# c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4320"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies_with_keyterms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_with_actors_directors(movies):\n",
    "    with open(\"Dataset\\\\credits.csv\", 'r', errors = 'ignore') as csvfile:\n",
    "        spamreader = csv.DictReader(csvfile)\n",
    "        for row in spamreader:\n",
    "            movie_id = int(row['id'])\n",
    "            if movies.get(movie_id) is None:\n",
    "                continue\n",
    "            actors = list()\n",
    "            cast = ast.literal_eval(row[\"cast\"])\n",
    "            for actor in cast:\n",
    "                actors.append(actor['name'].replace(\" \", \"\").lower())\n",
    "            movies[movie_id][\"actors\"] = actors    \n",
    "            crew = ast.literal_eval(row[\"crew\"])\n",
    "            directors = list()\n",
    "            for member in crew:\n",
    "                if member['job'].lower() == \"director\":\n",
    "                    directors.insert(0, member['name'].replace(\" \", \"\").lower())\n",
    "                elif 'director' in member['job'].lower():\n",
    "                    name = member['name'].replace(\" \", \"\").lower()\n",
    "                    directors.append(name)\n",
    "            movies[movie_id][\"directors\"] = directors    \n",
    "    return movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_with_keyterms_actors_directors = get_movie_with_actors_directors(movies_with_keyterms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = 0\n",
    "# ids = []\n",
    "# for k in movies_with_keyterms_actors_directors.keys():\n",
    "# #     print(movies_with_keyterms_actors_directors[k])\n",
    "#     if movies_with_keyterms_actors_directors[k].get(\"actors\") is None:\n",
    "#         ids.append(k)\n",
    "#         c += 1\n",
    "# c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4320"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies_with_keyterms_actors_directors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_genre_descr(movies, meta_data):\n",
    "    for row in meta_data:\n",
    "        if not row['id'].isdecimal():\n",
    "            continue\n",
    "        else:\n",
    "            movie_id = int(row['id'])\n",
    "        if movies.get(movie_id) is None:\n",
    "            continue\n",
    "        if row.get(\"overview\") is not None:\n",
    "            movies[movie_id][\"overview\"] = row.get(\"overview\")\n",
    "        else:\n",
    "            movies[movie_id][\"overview\"] = []\n",
    "        genres = list()\n",
    "        gs = ast.literal_eval(meta_data[0][\"genres\"])\n",
    "        for genre in gs:\n",
    "            genres.append(genre['name'].replace(\" \", \"\").lower())\n",
    "        movies[movie_id][\"genres\"] = genres\n",
    "    return movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_with_details_dic1 = get_movie_genre_descr(movies_with_keyterms_actors_directors, meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4320"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies_with_details_dic1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"movies_with_details_dic1\", 'wb') as fp:\n",
    "    pickle.dump(movies_with_details_dic1, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies_with_details_dic1[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_doc_1 = pickle.load(open(\"all_doc_1\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_dir_genr_key_docs1, overview_docs1, mapping1 = all_doc_1[0], all_doc_1[1], all_doc_1[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4320, 35227)\n",
      "(4320, 35227)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(actor_dir_genr_key_docs1)\n",
    "\n",
    "Y = X.toarray()\n",
    "print(Y.shape)\n",
    "\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "tfidf = transformer.fit_transform(Y)\n",
    "\n",
    "actor_dir_genr_key_docs_tfidf1 = tfidf.toarray()\n",
    "print(actor_dir_genr_key_docs_tfidf1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.03434226, 0.11782277, 0.12319205, 0.13612718,\n",
       "       0.15628231, 0.16805981, 0.20993127, 0.21566829, 0.21726589,\n",
       "       0.22070298, 0.23373551, 0.23947252, 0.25040894, 0.2602886 ,\n",
       "       0.29801742, 0.32182166])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(actor_dir_genr_key_docs_tfidf1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4320, 22180)\n",
      "(4320, 22180)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(overview_docs1)\n",
    "\n",
    "Y = X.toarray()\n",
    "print(Y.shape)\n",
    "\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "tfidf = transformer.fit_transform(Y)\n",
    "\n",
    "overview_docs_tfidf1 = tfidf.toarray()\n",
    "print(overview_docs_tfidf1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.03456126, 0.03872895, 0.04448264, 0.06443655,\n",
       "       0.06723324, 0.07146933, 0.07172676, 0.07582001, 0.07743921,\n",
       "       0.08304618, 0.08620849, 0.09354092, 0.09831381, 0.10106722,\n",
       "       0.10768204, 0.11302094, 0.12499617, 0.12776216, 0.13545372,\n",
       "       0.14157557, 0.14188657, 0.14283985, 0.14349298, 0.16103341,\n",
       "       0.16487234, 0.16627213, 0.17092233, 0.17177427, 0.17265165,\n",
       "       0.17854936, 0.18326183, 0.19046598, 0.19392763, 0.19582441,\n",
       "       0.20045113, 0.23467082, 0.24312579, 0.27541401])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(overview_docs_tfidf1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"actor_dir_genr_key_docs_tfidf1\", 'wb') as fp:\n",
    "    pickle.dump(actor_dir_genr_key_docs_tfidf1, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"overview_docs_tfidf1\", 'wb') as fp:\n",
    "    pickle.dump(overview_docs_tfidf1, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_dir_genr_sim_matr1 = cosine_similarity(actor_dir_genr_key_docs_tfidf1, actor_dir_genr_key_docs_tfidf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4320, 4320)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_dir_genr_sim_matr1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_sim_matr1 = cosine_similarity(overview_docs_tfidf1, overview_docs_tfidf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.02349546, 0.0089046 , ..., 0.00630869, 0.01638066,\n",
       "       0.02488871])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_sim_matr1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4320, 4320)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_sim_matr1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"actor_dir_genr_sim_matr1\", 'wb') as fp:\n",
    "    pickle.dump(actor_dir_genr_sim_matr1, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"overview_sim_matr1\", 'wb') as fp:\n",
    "    pickle.dump(overview_sim_matr1, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
